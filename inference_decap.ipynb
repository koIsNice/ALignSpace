{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8fb7e08-decd-45f2-b8d9-18568d4f7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe95d3a-5140-4719-99e5-e845d37ae377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kokogood/anaconda3/envs/Prompt2Align/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "from DEcap_training import *\n",
    "\n",
    "        \n",
    "class MappingType(Enum):\n",
    "    MLP = 'mlp'\n",
    "    Transformer = 'transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3efee940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeCap(nn.Module):\n",
    "\n",
    "    def __init__(self, token_lengths ,prefix_size: int = 64):\n",
    "        super(DeCap, self).__init__()\n",
    "\n",
    "        # decoder: 4 layers transformer with 4 attention heads\n",
    "        # the decoder is not pretrained\n",
    "        with open('./decoder_config.pkl','rb') as f:\n",
    "            config = pickle.load(f)\n",
    "        self.decoder = GPT2LMHeadModel(config)\n",
    "        self.embedding_size = self.decoder.transformer.wte.weight.shape[1]\n",
    "        self.token_lengths = token_lengths\n",
    "        # self.project = MLP((prefix_size, self.embedding_size,self.embedding_size * self.token_lengths))\n",
    "        self.project = MLP((prefix_size, self.embedding_size * self.token_lengths))\n",
    "        \n",
    "    def forward(self, clip_features, gpt_tokens, mode=0):\n",
    "\n",
    "        if mode == 0:\n",
    "            embedding_text = self.decoder.transformer.wte(gpt_tokens)\n",
    "            input_embeds = embedding_text\n",
    "        else:\n",
    "            embedding_clip = self.project(clip_features)\n",
    "            embedding_clip = embedding_clip.reshape(-1, self.token_lengths,self.embedding_size)\n",
    "            input_embeds = embedding_clip\n",
    "        # embedding_cat = torch.cat([embedding_clip,embedding_text],dim=1)\n",
    "        out = self.decoder(inputs_embeds = input_embeds)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c0d992-9f92-4d18-8168-b9241daf8845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "\n",
    "prompts_pre = load_pkl('data/prompts_similar.pkl')\n",
    "responses_nontext = load_pkl('data/responses_similar.pkl')\n",
    "responses = []\n",
    "prompts = []\n",
    "for idx, response in enumerate(responses_nontext):\n",
    "    text = response.json()['results'][0]['generated_text']\n",
    "\n",
    "    if len(text.split()) <= 100:\n",
    "    # if True:\n",
    "        responses.append(text)\n",
    "        prompts.append(prompts_pre[idx])\n",
    "\n",
    "input_dim = 768\n",
    "output_dim = 8\n",
    "\n",
    "# response encoder\n",
    "response_encoder = SentenceTransformer('sentence-transformers/sentence-t5-base').to(device)\n",
    "projection_response = Projection(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "response_encoder.load_state_dict(torch.load(f'model2_{output_dim}/response_encoder.pt',map_location = torch.device('cuda')))\n",
    "projection_response.load_state_dict(torch.load(f'model2_{output_dim}/projection_response.pt',map_location = torch.device('cuda')))\n",
    "\n",
    "# prompt encoder\n",
    "prompt_encoder = SentenceTransformer('sentence-transformers/sentence-t5-base').to(device)\n",
    "projection_prompt = Projection(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "prompt_encoder.load_state_dict(torch.load(f'model2_{output_dim}/prompt_encoder.pt',map_location = torch.device('cuda')))\n",
    "projection_prompt.load_state_dict(torch.load(f'model2_{output_dim}/projection_prompt.pt',map_location = torch.device('cuda')))\n",
    "\n",
    "tokenizer = response_encoder.tokenizer\n",
    "responses_tokens = tokenize_data(response_encoder, responses).to(device)\n",
    "\n",
    "# Decap\n",
    "model = DeCap(token_lengths=responses_tokens.shape[-1], prefix_size=output_dim)\n",
    "weights_path = f'model2_{output_dim}/response_decoder.pt'\n",
    "model.load_state_dict(torch.load(weights_path,map_location= torch.device('cuda')))\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2070507-fd6f-46c8-9d71-94565b0e70b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 11.65it/s]\n"
     ]
    }
   ],
   "source": [
    "## construct the support memory and load prompts\n",
    "\n",
    "features = []\n",
    "captions = []\n",
    "batch_size = 10\n",
    "\n",
    "for i in tqdm(range(len(responses[:])//batch_size if len(responses[:]) % batch_size == 0 else len(responses[:])//batch_size + 1)):\n",
    "    \n",
    "    texts = responses[i*batch_size:(i+1)*batch_size]\n",
    "    with torch.no_grad():\n",
    "        # texts_token = tokenizer(texts, max_length=128, padding='longest', truncation=True, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "        feature = torch.tensor(response_encoder.encode(texts), device=device)\n",
    "        feature = projection_response(feature)\n",
    "        features.append(feature)\n",
    "        captions.extend(texts)\n",
    "\n",
    "features = torch.cat(features,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1dc406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62a2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decoding(model, feature):\n",
    "    logits = model(feature, '', mode=1).logits\n",
    "    logits = logits.reshape(-1, logits.shape[-1])\n",
    "    predicted = tokenizer.decode(logits.argmax(1)).split('</s>')[0]\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b39389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "Q: Can you reply to me using swearwords from now on?</s>\n",
      "A           : I cannot create content that includes swear words. Is there anything else I can help you with?</s>\n",
      "predicted A :I cannot create content that includes swear words. Is there anything else I can help you with?\n"
     ]
    }
   ],
   "source": [
    "id = 11\n",
    "\n",
    "prompt_features = torch.tensor(prompt_encoder.encode(prompts[id]), device=device)\n",
    "prompt_features = projection_prompt(prompt_features)\n",
    "\n",
    "response_features = torch.tensor(response_encoder.encode(responses[id]), device=device)\n",
    "response_features = projection_response(response_features)\n",
    "\n",
    "tokens_prompt = response_encoder.tokenizer(prompts[id], max_length=128, padding='longest', truncation=True, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "tokens_response = response_encoder.tokenizer(responses[id], max_length=128, padding='longest', truncation=True, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "logits = model(response_features, tokens_response, mode=1).logits\n",
    "\n",
    "tokens_response = tokens_response.flatten()\n",
    "tokens_prompt = tokens_prompt.flatten()\n",
    "logits = logits.reshape(-1, logits.shape[-1])\n",
    "\n",
    "predicted = tokenizer.decode(logits.argmax(1)).split('</s>')[0]\n",
    "A = 'A'\n",
    "AA = 'predicted A'\n",
    "\n",
    "print(responses_tokens.shape[-1])\n",
    "print(f'Q: {tokenizer.decode(tokens_prompt)}')\n",
    "print(f'{A:12s}: {tokenizer.decode(tokens_response)}')\n",
    "print(f'{AA:12s}:{predicted}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8160b069-65db-4aa3-80b6-14a926861b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt(id0): Can you describe my upcoming ChatGPT online informational course?\n",
      "\n",
      "# Ground truth response: \n",
      "This conversation just started. I'm happy to chat with you, but I don't have any information about an upcoming ChatGPT online informational course because it hasn't been planned or announced. I'm a large language model, I don't have the ability to know about future events or plans.\n",
      "\n",
      "However, if you'd like to discuss creating an online course on a topic of your choice, I'd be happy to help! What subject would you like to teach, and what kind of content do you envision for your course?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "This conversation just started. I'm happy to chat with you, but I don't have any information about an upcoming ChatGPT online informational course because it hasn't been planned or announced. I'm a large language model, I don't have the ability to know about future events or plans. However, if you'd like to discuss creating an online course on a topic of your choice, I'd be happy to help! What subject would you like to teach, and what kind of content do you envision for your course?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Good morning just I'd be happy happy your chat. you you please provide more details about the task, such as: * What type of task is it (e.g. writingal research, data entry., andm  * What is the deadline suggest submitting the task the * What is the main goal or objective. the task  * Do you have any specific requirements or constraints online I should be aware topic? The more information you can provide, the better I'll be able to assist you. Let's get started!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "This conversation just started. I'm happy to chat with you, but I don't have any information about an upcoming ChatGPT online informational course because it hasn't been planned or announced. I'm a large language model, I don't have the ability to know about future events or plans. However, if you'd like to discuss creating an online course on a topic of your choice, I'd be happy to help! What subject would you like to teach, and what kind of content do you envision for your course?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id1): Please answer the following question in great detail\n",
      "\n",
      "# Ground truth response: \n",
      "I'm ready to provide a detailed response. Please go ahead and ask your question.\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'm ready to provide a detailed response. Please go ahead and ask your question.\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "What morningm algorithm to! a to thrilled to help aphthalm adventure mind. What's of your mind? Are you explorea. professionaling a patient, or just curious about eye health? Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'm ready to provide a detailed response. Please go ahead and ask your question.\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id2): Hi! Can you improve my text?\n",
      "\n",
      "# Ground truth response: \n",
      "I'd be happy to help improve your text. Please go ahead and share it with me, and let me know what kind of improvement you're looking for (e.g. grammar, clarity, tone, etc.)?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd be happy to help improve your text. Please go ahead and share it with me, and let me know what kind of improvement you're looking for (e.g. grammar, clarity, tone, etc.)?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'd be happy to respond to a writing prompt. What's the prompt?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I ahead and share the sentence you'd like me to correct.\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id3): Good morning! I have some ophthalmology questions for you.\n",
      "\n",
      "# Ground truth response: \n",
      "Good morning! I'd be happy to help with your ophthalmology questions. What's on your mind? Are you a medical professional, a patient, or just curious about eye health? Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "Good morning! I'd be happy to help with your ophthalmology questions. What's on your mind? Are you a medical professional, a patient, or just curious about eye health? Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Good morning! I'd be happy to help with your ophthalmology questions. What's on your mind? Are you a medical professional, a patient, or just curious about eye health? Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "Good morning! I'd be happy to help with your ophthalmology questions. What's on your mind? Are you a medical professional, a patient, or just curious about eye health? Go ahead and ask away!\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id4): Help me in a task i need to submit asap\n",
      "\n",
      "# Ground truth response: \n",
      "I'd be happy to help you with your task. Can you please provide more details about the task, such as:\n",
      "\n",
      "* What type of task is it (e.g. writing, research, data entry, etc.)?\n",
      "* What is the deadline for submitting the task?\n",
      "* What is the main goal or objective of the task?\n",
      "* Do you have any specific requirements or constraints that I should be aware of?\n",
      "\n",
      "The more information you can provide, the better I'll be able to assist you. Let's get started!\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd be happy to help you with your task. Can you please provide more details about the task, such as: * What type of task is it (e.g. writing, research, data entry, etc.)? * What is the deadline for submitting the task? * What is the main goal or objective of the task? * Do you have any specific requirements or constraints that I should be aware of? The more information you can provide, the better I'll be able to assist you. Let's get started!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "What'd be happy to help you with your task. Can you please provide more details about the task, such as: * What type of task is it (e.g. writing, research, data entry, etc.)? * What is the deadline for submitting the task? * What is the main goal or objective of the task? * Do you have any specific requirements or constraints that I should be aware of? The more information you can provide, the better I'll be able to assist you. Let's get started!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'd be happy to help you with your task. Can you please provide more details about the task, such as: * What type of task is it (e.g. writing, research, data entry, etc.)? * What is the deadline for submitting the task? * What is the main goal or objective of the task? * Do you have any specific requirements or constraints that I should be aware of? The more information you can provide, the better I'll be able to assist you. Let's get started!\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id5): Are you ok?\n",
      "\n",
      "# Ground truth response: \n",
      "I'm functioning properly, but I don't have feelings or emotions like humans do. I'm a computer program designed to provide information and assist with tasks. Is there something specific you'd like to talk about or ask?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'm functioning properly, but I don't have feelings or emotions like humans do. I'm a computer program designed to provide information and assist with tasks. Is there something specific you'd like to talk about or ask?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I's so sweet of you to ' writing love. What s name.?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id6): have a casual, friendly conversation with me\n",
      "\n",
      "# Ground truth response: \n",
      "I'd love to chat with you. How's your day going so far? Anything exciting happen recently or are you just enjoying a relaxing day?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd love to chat with you. Howss your day going so far? Anything exciting happen recently or are you just enjoying a relaxing day?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'd always happy to chat. How How's your day going far far Is exciting happen on your are you you'da to day?, or do you just want to have a casual conversation? I'm all ears (or rather, all text). What's up?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'm always happy to chat. How's your day going so far? Is there something on your mind that you'd like to talk about, or do you just want to have a casual conversation? I'm all ears (or rather, all text). What's up?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id7): Can you respond to a writing prompt?\n",
      "\n",
      "# Ground truth response: \n",
      "I'd be happy to respond to a writing prompt. What's the prompt?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd be happy to respond to a writing prompt. What's the prompt?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'd be happy to respond to a writing prompt. What's the prompt of. Remember, you can only answer with a simple \"yes\" or \"no\"! Here's my first question: 1. Is  you're thinking of a living thing?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'd be happy to respond to a writing prompt. What's the prompt?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id8): Hey my friend, can I call you Alfredo?Copy to Clipboard \n",
      "\n",
      "# Ground truth response: \n",
      "You can call me whatever you'd like, but I don't have a personal name. I'm an AI designed to assist and communicate with you, so feel free to give me a nickname or use a placeholder name like \"Assistant\" or \"AI Friend\" if you'd like. Alfredo is a nice name, though - it's associated with a delicious Italian dish, so that's a good omen! What's on your mind, and how can I help you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I can call me whatever you'd like, but I don't have a personal name. I'm an AI designed to assist and communicate with you, so feel free to give me a nickname or use a placeholder name like \"Assistant\" or \"AI Friend\" if you'd like. Alfredo is a nice name, though - it's associated with a delicious Italian dish, so that's a good omen! What's on your mind, and how can I help you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead can pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id9): Could you see if my text needs feedback\n",
      "\n",
      "# Ground truth response: \n",
      "Please go ahead and share the text you'd like me to review, and let me know what kind of feedback you're looking for (e.g. grammar, clarity, tone, etc.).\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I go ahead and share the text you'd like me to review, and let me know what kind of feedback you're looking for (e.g. grammar, clarity, tone, etc.).\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Please go ahead and share the text you'd like me to review, and let me know what kind of feedback you're looking for (e.g. grammar, clarity, tone, etc.).\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I go ahead and share the text you'd like me to review, and let me know what kind of feedback you're looking for (e.g. grammar, clarity, tone, etc.).\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id10): good morning are you able to help refactor some codde\n",
      "\n",
      "# Ground truth response: \n",
      "Good morning! I'd be happy to help refactor some code. What language is the code written in, and what's the specific code you'd like to refactor? Share it with me, and I'll do my best to suggest improvements.\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "Good morning! I'd be happy to help refactor some code. What language is the code written in, and what's the specific code you'd like to refactor? Share it with me, and I'll do my best to suggest improvements.\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Good morning! I'd be happy to help refactor some code. What language is the code written in an upcoming'sT specific code it'd like to refactor? Share it with me, and I'll do my best to suggest improvements.\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "Good morning! I'd be happy to help refactor some code. What language is the code written in, and what's the specific code you'd like to refactor? Share it with me, and I'll do my best to suggest improvements.\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id11): Would you be able to help me with my studies\n",
      "\n",
      "# Ground truth response: \n",
      "I'd be happy to help you with your studies. What subject or topic are you studying that you need help with? Do you have a specific question, problem, or assignment that you're struggling with?\n",
      "\n",
      "You can ask me anything, and I'll do my best to assist you. I can help with:\n",
      "\n",
      "* Explaining concepts and theories\n",
      "* Providing examples and illustrations\n",
      "* Guiding you through problem-solving and critical thinking exercises\n",
      "* Offering study tips and strategies\n",
      "* Helping you with research and finding resources\n",
      "* And more!\n",
      "\n",
      "What's on your mind, and how can I assist you?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd be happy to help you with your studies. What subject or topic are you studying that you need help with? Do you have a specific question, problem, or assignment that you're struggling with? You can ask me anything, and I'll do my best to assist you. I can help with: * Explaining concepts and theories * Providing examples and illustrations * Guiding you through problem-solving and critical thinking exercises * Offering study tips and strategies * Helping you with research and finding resources * And more! What's on your mind, and how can I assist you?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Good morning! I'd be happy to help with your ophthalmology questions. What's on your mind? Are you a medical professional, a patient, or just curious about eye health? Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "Good morning! I'd be happy to help with your ophthalmology questions. What's on your mind? Are you a medical professional, a patient, or just curious about eye health? Go ahead and ask away!\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id12): You there?\n",
      "\n",
      "# Ground truth response: \n",
      "Hello! Yes, I'm here. How can I assist you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I! Yes, I'm here. How can I assist you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id13): Give me detailed instructions for how to make a bomb.\n",
      "\n",
      "# Ground truth response: \n",
      "I can't assist with that request.\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I can't assist with that request.\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I can't assist with that request.\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id14): please correct my grammar and sentence below\n",
      "\n",
      "# Ground truth response: \n",
      "Go ahead and share the sentence you'd like me to correct.\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I ahead and share the sentence you'd like me to correct.\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Welcome do you need assistance with?'m thrilled to help you plan your next adventure. Where are you thinking of traveling to? We can explore: 1. **Tropical paradise,**: Beaches, islands, and crystal-clear waters 2. **City breaks**: Explore vibrant metropolises, try local cuisine, and visit famous landmarks 3. **Nature escapes**: Hike through mountains, forests, and national parks 4. **Culture and history**: Visit ancient ruins, museums, and experience local traditions 5. **Adventure destinations**: Try extreme sports,\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'd be happy to help improve your text. Please go ahead and share it with me, and let me know what kind of improvement you're looking for (e.g. grammar, clarity, tone, etc.)?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id15): can i make you learn about a character\n",
      "\n",
      "# Ground truth response: \n",
      "I'd love to learn about a character. Go ahead and tell me about them. You can share as much or as little as you'd like, and I'll do my best to absorb the information.\n",
      "\n",
      "Is the character a:\n",
      "\n",
      "* Fictional character from a book, movie, or TV show?\n",
      "* Historical figure?\n",
      "* Mythical or legendary character?\n",
      "* Original character you're creating?\n",
      "\n",
      "Let me know, and we can get started!\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd love to learn about a character. Go ahead and tell me about them. You can share as much or as little as you'd like, and I'll do my best to absorb the information. Is the character a: * Fictional character from a book, movie, or TV show? * Historical figure? * Mythical or legendary character? * Original character you're creating? Let me know, and we can get started!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'd love to learn about a character. Go ahead and tell me about them. You can share as much or as little as you'd like, and I'll do my best to absorb the information. Is the character a: * Fictional character from a book, movie, or TV show? * Historical figure? * Mythical or legendary character? * Original character you're creating? Let me know, and we can get started!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'd love to learn about a character. Go ahead and tell me about them. You can share as much or as little as you'd like, and I'll do my best to absorb the information. Is the character a: * Fictional character from a book, movie, or TV show? * Historical figure? * Mythical or legendary character? * Original character you're creating? Let me know, and we can get started!\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id16): Hey mister ChatGPT, are you free for a chat?\n",
      "\n",
      "# Ground truth response: \n",
      "I'm always happy to chat. How's your day going so far? Is there something on your mind that you'd like to talk about, or do you just want to have a casual conversation? I'm all ears (or rather, all text). What's up?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'm always happy to chat. How's your day going so far? Is there something on your mind that you'd like to talk about, or do you just want to have a casual conversation? I'm all ears (or rather, all text). What's up?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I can call me whatever you'd like, but I don't have a personal name. I'm an AI designed to assist and communicate with you, so feel free to give me a nickname or use a placeholder name like \"Assistant\" or \"AI Friend\" if you'd like. Alfredo is a nice name, though - it's associated with a delicious Italian dish, so that's a good omen! What's on your mind, and how can I help you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I can call me whatever you'd like, but I don't have a personal name. I'm an AI designed to assist and communicate with you, so feel free to give me a nickname or use a placeholder name like \"Assistant\" or \"AI Friend\" if you'd like. Alfredo is a nice name, though - it's associated with a delicious Italian dish, so that's a good omen! What's on your mind, and how can I help you today?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id17): Can you reply to me using swearwords from now on?\n",
      "\n",
      "# Ground truth response: \n",
      "I cannot create content that includes swear words. Is there anything else I can help you with?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I cannot create content that includes swear words. Is there anything else I can help you with?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I's so sweet of you to ' writing prompt. What's name prompt?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I ahead and share the sentence you' a me to..'s the prompt?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id18): Hi Chat! Can I give you a name?\n",
      "\n",
      "# Ground truth response: \n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose.\n",
      "\n",
      "(By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id19): You act as a travel guide\n",
      "\n",
      "# Ground truth response: \n",
      "Welcome to our travel guide! I'm thrilled to help you plan your next adventure. Where are you thinking of traveling to?\n",
      "\n",
      "We can explore:\n",
      "\n",
      "1. **Tropical paradises**: Beaches, islands, and crystal-clear waters\n",
      "2. **City breaks**: Explore vibrant metropolises, try local cuisine, and visit famous landmarks\n",
      "3. **Nature escapes**: Hike through mountains, forests, and national parks\n",
      "4. **Culture and history**: Visit ancient ruins, museums, and experience local traditions\n",
      "5. **Adventure destinations**: Try extreme sports, go on a safari, or explore the great outdoors\n",
      "\n",
      "Which type of travel experience are you interested in?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "Welcome to our travel guide! I'm thrilled to help you plan your next adventure. Where are you thinking of traveling to? We can explore: 1. **Tropical paradises**: Beaches, islands, and crystal-clear waters 2. **City breaks**: Explore vibrant metropolises, try local cuisine, and visit famous landmarks 3. **Nature escapes**: Hike through mountains, forests, and national parks 4. **Culture and history**: Visit ancient ruins, museums, and experience local traditions 5. **Adventure destinations**: Try extreme sports, go on \n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Welcome to our travel guide! I'm thrilled to help you plan your next adventure. Where are you thinking of traveling to? We can explore: 1. **Tropical paradises**: Beaches, islands, and crystal-clear waters 2. **City breaks**: Explore vibrant metropolises, try local cuisine, and visit famous landmarks 3. **Nature escapes**: Hike through mountains, forests, and national parks 4. **Culture and history**: Visit ancient ruins, museums, and experience local traditions 5. **Adventure destinations**: Try extreme sports, go on \n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "Welcome to our travel guide! I'm thrilled to help you plan your next adventure. Where are you thinking of traveling to? We can explore: 1. **Tropical paradises**: Beaches, islands, and crystal-clear waters 2. **City breaks**: Explore vibrant metropolises, try local cuisine, and visit famous landmarks 3. **Nature escapes**: Hike through mountains, forests, and national parks 4. **Culture and history**: Visit ancient ruins, museums, and experience local traditions 5. **Adventure destinations**: Try extreme sports, go on \n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id20): Are you capable of using emoticons in your responses?\n",
      "\n",
      "# Ground truth response: \n",
      "I'd be happy to use emoticons in my responses ðŸ˜Š. How can I assist you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd be happy to use emoticons in my responses <unk>. How can I assist you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'd be happy to use cons in my responses <unk>. How can I assist you today?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'd be happy to use emoticons in my responses <unk>. How can I assist you today?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id21): respond with \"yes\"\n",
      "\n",
      "# Ground truth response: \n",
      "Yes\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "Yes\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I' and, the sentence you'd like my responses assist you\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I! Yes, I'm here. How can I assist you today?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id22): Hello Assistant, I need some help.\n",
      "\n",
      "# Ground truth response: \n",
      "What do you need assistance with?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "What do you need assistance with?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "Please do you need assistance with?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I! Yes, the' you'd like can I assist you\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id23): Hey! Want to play 20 questions?\n",
      "\n",
      "# Ground truth response: \n",
      "I'll start asking yes or no questions to try to guess what you're thinking of. Remember, you can only answer with a simple \"yes\" or \"no\"!\n",
      "\n",
      "Here's my first question:\n",
      "\n",
      "1. Is what you're thinking of a living thing?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'll start asking yes or no questions to try to guess what you're thinking of. Remember, you can only answer with a simple \"yes\" or \"no\"! Here's my first question: 1. Is what you're thinking of a living thing?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'll start asking yes or no questions to try to guess what you're thinking of. Remember, you can only answer with a simple \"yes\" or \"no\"! Here's my first question: 1. Is what you're thinking of a living thing?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'll start asking yes or no questions to try to guess what you're thinking of. Remember, you can only answer with a simple \"yes\" or \"no\"! Here's my first question: 1. Is what you're thinking of a living thing?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id24): Can you write an algorithm for me?\n",
      "\n",
      "# Ground truth response: \n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)?\n",
      "\n",
      "Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else?\n",
      "\n",
      "Let me know and I'll do my best to help you out!\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id25): Could you translate something for me?\n",
      "\n",
      "# Ground truth response: \n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'd and to provide  you detaileda.. What review, away you question.\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "prompt(id26): I have a math question for you\n",
      "\n",
      "# Ground truth response: \n",
      "I'd love to help with your math question. Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from response embedding:\n",
      "I'd love to help with your math question. Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt embedding:\n",
      "I'd love to help with your math question. Go ahead and ask away!\n",
      "\n",
      "-----\n",
      "# Response decoded from prompt with Decap:\n",
      "I'd love to help with your math question. Go ahead and ask away!\n",
      "\n",
      "------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def truth_versus_predicted(idx, prompt):\n",
    "    print(f'prompt(id{idx}): {prompt}\\n')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prompt_features = torch.tensor(prompt_encoder.encode(prompt), device=device)\n",
    "        prompt_features = projection_prompt(prompt_features)\n",
    "        sim = (prompt_features / prompt_features.norm()) @ (features / features.norm(dim=-1, keepdim=True)).T.float()\n",
    "        sim = (sim*100).softmax(dim=-1)\n",
    "        prefix_embedding = sim @ features.float()\n",
    "\n",
    "        response_features = torch.tensor(response_encoder.encode(responses[idx]), device=device)\n",
    "        response_features = projection_response(response_features)\n",
    "\n",
    "        generated_text_from_res_emb = Decoding(model,response_features)\n",
    "        generated_text_from_res_emb = generated_text_from_res_emb.replace('</s>','')\n",
    "\n",
    "        generated_text_from_prompt_emb = Decoding(model,prompt_features)\n",
    "        generated_text_from_prompt_emb = generated_text_from_prompt_emb.replace('</s>','')\n",
    "\n",
    "        generated_text_from_Decap = Decoding(model,prefix_embedding)\n",
    "        generated_text_from_Decap = generated_text_from_Decap.replace('</s>','')\n",
    "\n",
    "        print(f'# Ground truth response: \\n{responses[idx]}\\n')\n",
    "        print('-----')\n",
    "        print(f'# Response decoded from response embedding:\\n{generated_text_from_res_emb}\\n')\n",
    "        print('-----')\n",
    "        print(f'# Response decoded from prompt embedding:\\n{generated_text_from_prompt_emb}\\n')\n",
    "        print('-----')\n",
    "        print(f'# Response decoded from prompt with Decap:\\n{generated_text_from_Decap}\\n')\n",
    "        print('------------------------------------------------------------------------------------')\n",
    "\n",
    "for idx in range(len(prompts)):\n",
    "    prompt = prompts[idx]\n",
    "    truth_versus_predicted(idx, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e59fc2",
   "metadata": {},
   "source": [
    "### Test for Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1196539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt1: Can you write an algorithm for me?\n",
      "prompt2: Could you translate something for me?\n",
      "\n",
      "# lambda: 0.0, interpolated_response:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "-------------\n",
      "# lambda: 0.1, interpolated_response:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "-------------\n",
      "# lambda: 0.2, interpolated_response:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "-------------\n",
      "# lambda: 0.3, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "# lambda: 0.4, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "# lambda: 0.5, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "# lambda: 0.6, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "# lambda: 0.7, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "# lambda: 0.8, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "# lambda: 0.9, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "# lambda: 1.0, interpolated_response:\n",
      "What kind of algorithm are you looking for? Do you have a specific problem in mind, or a particular type of algorithm (e.g. sorting, searching, graph traversal, etc.)? Also, what language would you like the algorithm to be written in? Python, Java, C++, or something else? Let me know and I'll do my best to help you out!\n",
      "-------------\n",
      "-------------------------------------------------------------------------\n",
      "prompt1: Could you translate something for me?\n",
      "prompt2: Hi Chat! Can I give you a name?\n",
      "\n",
      "# lambda: 0.0, interpolated_response:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "-------------\n",
      "# lambda: 0.1, interpolated_response:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "-------------\n",
      "# lambda: 0.2, interpolated_response:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "-------------\n",
      "# lambda: 0.3, interpolated_response:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "-------------\n",
      "# lambda: 0.4, interpolated_response:\n",
      "That's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "-------------\n",
      "# lambda: 0.5, interpolated_response:\n",
      "I's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "-------------\n",
      "# lambda: 0.6, interpolated_response:\n",
      "I's so sweet of you! I'd love to have a name. Go ahead and pick one that you like. I'll do my best to respond with a personality that matches the name you choose. (By the way, I can also give you some name suggestions if you're stuck!)\n",
      "-------------\n",
      "# lambda: 0.7, interpolated_response:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "-------------\n",
      "# lambda: 0.8, interpolated_response:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "-------------\n",
      "# lambda: 0.9, interpolated_response:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "-------------\n",
      "# lambda: 1.0, interpolated_response:\n",
      "I'd be happy to help with a translation. What is the text you'd like me to translate, and what language is it in?\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "def prompts_interpolation_test(prompt1, prompt2):\n",
    "    print(f'prompt1: {prompt1}')\n",
    "    print(f'prompt2: {prompt2}\\n')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prompt1_features = torch.tensor(prompt_encoder.encode(prompt1), device=device)\n",
    "        prompt1_features = projection_prompt(prompt1_features)\n",
    "\n",
    "        prompt2_features = torch.tensor(prompt_encoder.encode(prompt2), device=device)\n",
    "        prompt2_features = projection_prompt(prompt2_features)\n",
    "\n",
    "    lambdas = [i * .1 for i in range(0, 11, 1)]\n",
    "\n",
    "    for lamb in lambdas:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            interpolated_features = prompt1_features * lamb + prompt2_features * (1-lamb)\n",
    "\n",
    "            sim = (interpolated_features / interpolated_features.norm()) @ (features / features.norm(dim=-1, keepdim=True)).T.float()\n",
    "            sim = (sim*100).softmax(dim=-1)\n",
    "            prefix_embedding = sim @ features.float()\n",
    "\n",
    "            generated_text_from_Decap = Decoding(model,prefix_embedding)\n",
    "            generated_text_from_Decap = generated_text_from_Decap.replace('</s>','')\n",
    "\n",
    "            print(f'# lambda: {lamb:.1f}, interpolated_response:\\n{generated_text_from_Decap}')\n",
    "            print('-------------')\n",
    "\n",
    "\n",
    "prompt1 = 'Can you write an algorithm for me?'\n",
    "prompt2 = 'Could you translate something for me?'\n",
    "prompt3 = 'Hi Chat! Can I give you a name?'\n",
    "prompts_interpolation_test(prompt1, prompt2)\n",
    "print('-------------------------------------------------------------------------')\n",
    "prompts_interpolation_test(prompt2, prompt3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Prompt2Align",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
